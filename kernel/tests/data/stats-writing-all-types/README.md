# stats-writing-all-types

Golden table for validating that kernel's `collect_stats()` produces file statistics
matching Spark's output.

## Table details

- **Engine**: Apache Spark 3.5.8 / Delta Lake 3.3.2
- **Generated by**: PySpark script
- **Reader/writer version**: reader v3, writer v7
- **Table features**: `columnMapping` (name mode), `timestampNtz`

## Schema

| Column             | Type                                        |
|--------------------|---------------------------------------------|
| byte_col           | byte                                        |
| short_col          | short                                       |
| int_col            | integer                                     |
| long_col           | long                                        |
| float_col          | float                                       |
| double_col         | double                                      |
| date_col           | date                                        |
| timestamp_col      | timestamp                                   |
| timestamp_ntz_col  | timestamp_ntz                               |
| string_col         | string                                      |
| decimal_col        | decimal(10,2)                               |
| boolean_col        | boolean                                     |
| binary_col         | binary                                      |
| array_col          | array\<integer\>                            |
| map_col            | map\<string, integer\>                      |
| nested_struct      | struct\<inner_int, inner_string, inner_double\> |

## Contents

- **Commit 0**: Table creation (empty, 0 rows)
- **Commit 1**: Append of 4 rows with 1 null per column, covering all stat-eligible types
  plus complex types (array, map) that have only nullCount stats
