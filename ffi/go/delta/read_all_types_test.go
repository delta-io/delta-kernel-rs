package delta

import (
	"fmt"
	"os"
	"strings"
	"testing"

	"github.com/stretchr/testify/require"
)

func TestReadAllPrimitiveTypes(t *testing.T) {
	path := "../../../acceptance/tests/dat/out/reader_tests/generated/all_primitive_types/delta"

	snapshot, err := NewSnapshot(path)
	require.NoError(t, err)
	defer snapshot.Close()

	scan, err := snapshot.Scan()
	require.NoError(t, err)
	defer scan.Close()

	schema, err := scan.LogicalSchema()
	require.NoError(t, err)

	t.Logf("Schema has %d fields:", len(schema.Fields))
	for _, field := range schema.Fields {
		t.Logf("  - %s: %s", field.Name, field.DataType)
	}

	// Get metadata iterator to find files
	iter, err := scan.MetadataIterator(snapshot.Engine())
	require.NoError(t, err)
	defer iter.Close()

	// Collect file metadata
	collector := &testFileCollector{
		t:        t,
		snapshot: snapshot,
		scan:     scan,
	}

	for {
		hasMore, err := iter.Next(collector)
		require.NoError(t, err)
		if !hasMore {
			break
		}
	}

	require.True(t, len(collector.files) > 0, "Should have at least one file")

	// Read the first file
	firstFile := collector.files[0]
	t.Logf("\nReading file: %s", firstFile.Path)

	readIter, err := scan.ReadFile(snapshot.Engine(), firstFile)
	require.NoError(t, err)
	defer readIter.Close()

	dataVisitor := &testDataVisitor{
		t:        t,
		snapshot: snapshot,
		schema:   schema,
	}

	for {
		hasMore, err := readIter.Next(dataVisitor)
		require.NoError(t, err)
		if !hasMore {
			break
		}
	}

	require.True(t, dataVisitor.batchCount > 0, "Should have read at least one batch")
	require.True(t, dataVisitor.totalRows > 0, "Should have read at least one row")

	t.Logf("\n✓ Successfully read %d batches with %d total rows", dataVisitor.batchCount, dataVisitor.totalRows)
	t.Logf("✓ All primitive types can be read!")

	// Write canonical output to file
	canonicalFile := "testdata/all_types_canon.txt"
	canonicalContent := fmt.Sprintf("# Canonical output for all_primitive_types Delta table\n")
	canonicalContent += fmt.Sprintf("# Generated by TestReadAllPrimitiveTypes\n")
	canonicalContent += fmt.Sprintf("# Table path: %s\n", path)
	canonicalContent += fmt.Sprintf("# Total batches: %d, Total rows: %d\n", dataVisitor.batchCount, dataVisitor.totalRows)
	canonicalContent += fmt.Sprintf("#\n# Schema (%d fields):\n", len(schema.Fields))
	for i, field := range schema.Fields {
		canonicalContent += fmt.Sprintf("#   [%d] %s: %s (nullable=%v)\n", i, field.Name, field.DataType, field.Nullable)
	}
	canonicalContent += "\n"
	canonicalContent += dataVisitor.output.String()

	err = os.WriteFile(canonicalFile, []byte(canonicalContent), 0644)
	require.NoError(t, err)
	t.Logf("✓ Canonical output written to %s", canonicalFile)
}

type testFileCollector struct {
	t        *testing.T
	snapshot *Snapshot
	scan     *Scan
	files    []*FileMeta
}

func (c *testFileCollector) VisitScanMetadata(metadata *ScanMetadata) bool {
	fileVisitor := &testFileVisitor{
		t:         c.t,
		scan:      c.scan,
		collector: c,
	}
	err := metadata.VisitFiles(fileVisitor)
	require.NoError(c.t, err)
	return true
}

type testFileVisitor struct {
	t         *testing.T
	scan      *Scan
	collector *testFileCollector
}

func (v *testFileVisitor) VisitFile(path string, size int64, stats *Stats, partitionValues map[string]string) {
	tableRoot, err := v.scan.TableRoot()
	require.NoError(v.t, err)

	fullPath := tableRoot + path
	v.collector.files = append(v.collector.files, &FileMeta{
		Path: fullPath,
		Size: uint64(size),
	})
}

type testDataVisitor struct {
	t          *testing.T
	snapshot   *Snapshot
	schema     *Schema
	batchCount int
	totalRows  uint64
	output     strings.Builder // Collect output for file writing
}

func (v *testDataVisitor) VisitEngineData(data *EngineData) bool {
	v.batchCount++
	length := data.Length()
	v.totalRows += length

	logMsg := fmt.Sprintf("\n  Batch #%d: %d rows", v.batchCount, length)
	v.t.Log(logMsg)
	v.output.WriteString(logMsg + "\n")

	if length == 0 {
		return true
	}

	// Get Arrow data
	arrowData, err := data.GetArrowData(v.snapshot.Engine())
	require.NoError(v.t, err)

	numCols := arrowData.NumColumns()
	numRows := arrowData.NumRows()

	require.Equal(v.t, int64(len(v.schema.Fields)), numCols, "Column count should match schema")
	require.Equal(v.t, int64(length), numRows, "Row count should match")

	// Print header (first batch only)
	if v.batchCount == 1 {
		headerMsg := "\n  Column names and types:\n"
		v.t.Log(headerMsg)
		v.output.WriteString(headerMsg)

		for col := 0; col < int(numCols); col++ {
			colName := arrowData.ColumnName(col)
			colFormat := arrowData.ColumnFormat(col)
			colMsg := fmt.Sprintf("    [%d] %s (%s)\n", col, colName, colFormat)
			v.t.Log(colMsg)
			v.output.WriteString(colMsg)
		}
	}

	// Print all rows
	dataMsg := "\n  Data rows:\n"
	v.t.Log(dataMsg)
	v.output.WriteString(dataMsg)

	for row := int64(0); row < numRows; row++ {
		rowMsg := fmt.Sprintf("    Row %d:\n", row)
		v.t.Log(rowMsg)
		v.output.WriteString(rowMsg)

		for col := 0; col < int(numCols); col++ {
			colName := arrowData.ColumnName(col)
			value, isValid := arrowData.GetValue(col, row)

			var valueMsg string
			if isValid {
				valueMsg = fmt.Sprintf("      %s: %v\n", colName, formatValue(value))
			} else {
				valueMsg = fmt.Sprintf("      %s: NULL\n", colName)
			}
			v.t.Log(valueMsg)
			v.output.WriteString(valueMsg)

			// Verify we can read the value (not nil, false which indicates unsupported type)
			if !isValid && value == nil {
				// Check if this is expected (null value) or an error (unsupported type)
				// For unsupported types, GetValue returns (nil, false)
				warnMsg := fmt.Sprintf("      Warning: Could not read value for column %s\n", colName)
				v.t.Log(warnMsg)
				v.output.WriteString(warnMsg)
			}
		}
	}

	return true
}

func formatValue(value interface{}) string {
	switch v := value.(type) {
	case []byte:
		// Show actual byte values as array
		if len(v) == 0 {
			return "[]"
		}
		// Format as array of numbers
		result := "["
		for i, b := range v {
			if i > 0 {
				result += ", "
			}
			result += fmt.Sprintf("%d", b)
		}
		result += "]"
		return result
	case int32, int64, int16, int8:
		return fmt.Sprintf("%d", v)
	case float32, float64:
		return fmt.Sprintf("%f", v)
	case bool:
		return fmt.Sprintf("%t", v)
	case string:
		if len(v) > 50 {
			return fmt.Sprintf("%q... (%d chars)", v[:50], len(v))
		}
		return fmt.Sprintf("%q", v)
	default:
		return fmt.Sprintf("%v", v)
	}
}
